{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeGGRY58R6aWxAprAMTxLe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7lucss/Projeto_Imersao/blob/main/chatbot_emocional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1mGTQ4dZWdxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c1859c-d019-4f2b-c4a0-74c00e0b05fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "# instalando o SDK do Google\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install colorama\n",
        "\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "api_key=userdata.get(\"key\")\n",
        "genai.configure(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# listar modelos disponíveis\n",
        "for x in genai.list_models():\n",
        "  if \"generateContent\" in x.supported_generation_methods:\n",
        "    print(x.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "FIDtikDsbXY-",
        "outputId": "7fac69a8-3748-4acb-96a7-a79f1e2192f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurando temperartura do chatbot\n",
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "}\n"
      ],
      "metadata": {
        "id": "-MF_X4f3dKoQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segurança de conteúdo do bot\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "VPevOF9Ld4xS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicializando modelo\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                             generation_config=generation_config,\n",
        "                             safety_settings=safety_settings)\n",
        "\n",
        "# adicionar entrada para permitir que o usuário ajuste a temperatura das respostas do chatbot\n",
        "# aqui também tem gerenciamento de erros, caso coloque um valor não correspondente, o programa irá pedir para colocar novamente um novo valor\n",
        "while True:\n",
        "  try:\n",
        "    temperature = float(input(\"Digite a temperatura desejada para as respostas do chatbot (entre 0.1 e 1.0): \"))\n",
        "    if 0.1 <= temperature <= 1.0:\n",
        "      break\n",
        "    else:\n",
        "      print(\"Temperatura inválida. Digite um valor entre 0.1 e 1.0.\")\n",
        "  except ValueError:\n",
        "    print(\"Entrada inválida. Digite um número válido.\")\n",
        "generation_config[\"temperature\"] = temperature\n",
        "\n",
        "# importação do módulo colorama\n",
        "from colorama import Fore, Style\n",
        "import random\n",
        "\n",
        "\n",
        "#lista de respostas\n",
        "respostas_tristes = [\n",
        "    \"Eu sinto muito que você esteja se sentindo assim. É importante cuidar de si mesmo e buscar apoio quando necessário.\",\n",
        "    \"Estou aqui para você. Se precisar desabafar ou conversar, estou à disposição.\",\n",
        "    \"Às vezes, é difícil lidar com nossas emoções. Saiba que você não está sozinho e pode contar comigo para apoio.\",\n",
        "]\n",
        "\n",
        "respostas_ansiosas = [\n",
        "    \"Parece que você está se sentindo ansioso. Respire fundo e tente se acalmar. Se precisar de alguém para conversar, estou aqui.\",\n",
        "    \"A ansiedade pode ser avassaladora, mas lembre-se de que você é mais forte do que pensa. Estou aqui para ajudar no que for necessário.\",\n",
        "    \"Respire fundo e tente se concentrar no momento presente. Você não está sozinho nessa luta contra a ansiedade.\",\n",
        "]\n",
        "\n",
        "def get_empathetic_response(user_input):\n",
        "    # lista de palavras-chave associadas a diferentes emoções\n",
        "    palavra_triste = [\"triste\", \"solitário\", \"deprimido\"]\n",
        "    palavra_ansiosa = [\"ansioso\", \"nervoso\", \"preocupado\"]\n",
        "\n",
        "    # traz resposta da lista triste\n",
        "    for palavra in palavra_triste:\n",
        "        if palavra in user_input:\n",
        "            return random.choice(respostas_tristes)\n",
        "\n",
        "    # traz resposta da lista ansiosa\n",
        "    for palavra in palavra_ansiosa:\n",
        "        if palavra in user_input:\n",
        "            return random.choice(respostas_ansiosas)\n",
        "\n",
        "\n",
        "# função para ter a resposta do chatbot\n",
        "def get_response(prompt, chat):\n",
        "    user_input = prompt.lower()\n",
        "\n",
        "    # resposta empática com base na entrada do usuário\n",
        "    resposta_empatica = get_empathetic_response(user_input)\n",
        "\n",
        "    # se uma resposta empática específica for encontrada, retorna essa resposta\n",
        "    if resposta_empatica:\n",
        "        return resposta_empatica\n",
        "\n",
        "    # caso contrário, envia a mensagem para o chatbot e retorna a resposta padrão\n",
        "    response = chat.send_message(prompt)\n",
        "    return response.text\n",
        "\n",
        "\n",
        "# funçao do chat\n",
        "def start_chat(model):\n",
        "    chat = model.start_chat(history=[])\n",
        "    print(Fore.BLUE + \"Bem-vindo ao Chat de Suporte Emocional e Psicossocial! Digite 'Fim' quando quiser finalizar a conversa.\" + Style.RESET_ALL)\n",
        "    while True:\n",
        "        prompt = input(\"Você: \")\n",
        "        if prompt.lower() == \"fim\":\n",
        "            print(Fore.BLUE + \"Obrigado por usar nosso serviço de suporte emocional. Até logo!\" + Style.RESET_ALL)\n",
        "            break\n",
        "        else:\n",
        "            response = get_response(prompt, chat)\n",
        "            print(Fore.RED + \"Bot:\" + Style.RESET_ALL + response)\n",
        "\n",
        "    return chat\n",
        "\n",
        "# botando pra funcionar\n",
        "chat = start_chat(model)\n",
        "\n",
        "# histórico de mensagens\n",
        "print(\"\\nHistórico de Mensagens:\")\n",
        "print(\"-------------------------------------------------------------------------------------------------------\")\n",
        "for message in chat.history:\n",
        "    if message.role == 'Usuário':\n",
        "        print(f'Você: {message.parts[0].text}')\n",
        "    else:\n",
        "        print(f'Bot: {message.parts[0].text}')\n",
        "    print(\"-------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-iHjQTqcfEVf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}